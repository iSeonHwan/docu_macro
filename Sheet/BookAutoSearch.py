import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import time
from openpyxl import load_workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Font
from openpyxl.worksheet.hyperlink import Hyperlink

# ğŸ“ ì…ë ¥ ë° ì¶œë ¥ íŒŒì¼ ì„¤ì •
INPUT_FILE = "book_titles_only.xlsx"
OUTPUT_FILE = "ë„ì„œ_ìë™ì™„ì„±_YES24_í•˜ì´í¼ë§í¬ë²„ì „.xlsx"

# ğŸ§  YES24 ê²€ìƒ‰ í•¨ìˆ˜
def search_yes24(title):
    """
    ë„ì„œëª…(title)ì„ YES24ì—ì„œ ê²€ìƒ‰í•œ í›„,
    ê°€ê²©, ì¶œíŒì‚¬, ë°œí–‰ì—°ë„, URLì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    base_url = "https://www.yes24.com/Product/Search?domain=ALL&query="
    search_url = base_url + requests.utils.quote(title)
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        res = requests.get(search_url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")

        # ğŸ” ì²« ë²ˆì§¸ ë„ì„œ ì •ë³´ ì°¾ê¸°
        item = soup.select_one("ul#yesSchList li")  # ë„ì„œ ë¦¬ìŠ¤íŠ¸ì˜ ì²« í•­ëª©

        if not item:
            return None

        # ğŸ’° ê°€ê²© ì¶”ì¶œ
        price_tag = item.select_one(".yes_b")  # class="yes_b"ì— ê°€ê²© ì¡´ì¬
        price = int(re.sub(r"[^\d]", "", price_tag.text)) if price_tag else None

        # ğŸ”— ë„ì„œ ìƒì„¸ ë§í¬ ì¶”ì¶œ
        link_tag = item.select_one("a.gd_name")
        book_url = "https://www.yes24.com" + link_tag["href"] if link_tag else ""

        # ğŸ“š ì¶œíŒì‚¬ì™€ ë°œí–‰ì¼ ì¶”ì¶œ
        detail_tag = item.select_one(".authPub.info_auth")  # ì €ì/ì¶œíŒì‚¬/ì¶œê°„ì¼ ì„ì¸ íƒœê·¸
        pub_text = detail_tag.text.strip() if detail_tag else ""
        publisher, pub_year = "", ""

        # ì˜ˆì‹œ: "ì†í˜„ì£¼ ì € | íŠ¹ë³„í•œì„œì¬ | 2021ë…„ 10ì›” 15ì¼"
        parts = [p.strip() for p in pub_text.split("|")]
        if len(parts) >= 2:
            publisher = parts[1]
        if len(parts) >= 3:
            match = re.search(r"\d{4}", parts[2])
            pub_year = match.group() if match else ""

        return {
            "ì˜ˆìƒë‹¨ê°€": price,
            "ì¶œíŒì‚¬": publisher,
            "ë°œí–‰ ì—°ë„": pub_year,
            "ì¶œì²˜(URL)": book_url,
            "ë¹„ê³ ": "ì„±ê³µ"
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return None

# ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel(INPUT_FILE)
df.columns = df.columns.str.strip().str.replace(" ", "").str.replace("\n", "")  # ì—´ ì´ë¦„ ì •ë¦¬

results = []

print(f"\nğŸ“š ì´ {len(df)}ê¶Œ ìë™ ê²€ìƒ‰ ì‹œì‘...\n")

# ğŸ” ê° ë„ì„œì— ëŒ€í•´ YES24 ê²€ìƒ‰
for idx, row in df.iterrows():
    title = str(row["ì‹ ì²­ë„ì„œëª…"]).strip()
    print(f"[{idx+1}] '{title}' ê²€ìƒ‰ ì¤‘...")

    result = search_yes24(title)
    if result:
        row["ì˜ˆìƒë‹¨ê°€"] = result["ì˜ˆìƒë‹¨ê°€"]
        row["ì¶œíŒì‚¬"] = result["ì¶œíŒì‚¬"]
        row["ë°œí–‰ ì—°ë„"] = result["ë°œí–‰ ì—°ë„"]
        row["ì¶œì²˜(URL)"] = result["ì¶œì²˜(URL)"]
        row["ë¹„ê³ "] = result["ë¹„ê³ "]
        print(f"   âœ… ê°€ê²©: {result['ì˜ˆìƒë‹¨ê°€']}ì› | ì¶œíŒì‚¬: {result['ì¶œíŒì‚¬']} | ì—°ë„: {result['ë°œí–‰ ì—°ë„']}")
    else:
        row["ë¹„ê³ "] = "ê²€ìƒ‰ ì‹¤íŒ¨"
        print("   âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨!")

    results.append(row)
    time.sleep(1)  # ê³¼ë¶€í•˜ ë°©ì§€

# ğŸ’¾ í•˜ì´í¼ë§í¬ í¬í•¨í•˜ì—¬ ì €ì¥
df_out = pd.DataFrame(results)

# ì—‘ì…€ ì“°ê¸° + í•˜ì´í¼ë§í¬ í¬í•¨
wb = load_workbook(INPUT_FILE)
ws = wb.active
ws.title = "ìë™ì™„ì„±ê²°ê³¼"

# ê¸°ì¡´ ë‚´ìš© ì œê±°
for row in ws.iter_rows(min_row=2):
    for cell in row:
        cell.value = None

# ìƒˆ ë‚´ìš© ì¶”ê°€
for r_idx, row in enumerate(dataframe_to_rows(df_out, index=False, header=True), start=1):
    for c_idx, value in enumerate(row, start=1):
        cell = ws.cell(row=r_idx, column=c_idx, value=value)
        if r_idx > 1 and df_out.columns[c_idx - 1] == "ì¶œì²˜(URL)" and isinstance(value, str) and value.startswith("http"):
            cell.hyperlink = value
            cell.font = Font(color="0000FF", underline="single")

wb.save(OUTPUT_FILE)
print(f"\nâœ… ì™„ë£Œ! '{OUTPUT_FILE}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
